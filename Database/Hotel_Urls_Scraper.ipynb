{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "print(\"Libraries Imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all module are loaded \n"
     ]
    }
   ],
   "source": [
    "# Spoofer code\n",
    "try:\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    from fp.fp import FreeProxy\n",
    "    from fake_useragent import UserAgent\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver import Chrome\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.common.exceptions import TimeoutException\n",
    "    import time\n",
    "    print('all module are loaded ')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(\"Error ->>>: {} \".format(e))\n",
    "\n",
    "\n",
    "class Spoofer(object):\n",
    "\n",
    "    def __init__(self, country_id=['US', 'HK'], rand=True, anonym=True):\n",
    "        self.country_id = country_id\n",
    "        self.rand = rand\n",
    "        self.anonym = anonym\n",
    "        self.userAgent, self.ip = self.get()\n",
    "\n",
    "    def get(self):\n",
    "        ua = UserAgent()\n",
    "        proxy = FreeProxy(country_id=self.country_id, rand=self.rand, anonym=self.anonym).get()\n",
    "        ip = proxy.split(\"://\")[1]\n",
    "        return ua.random, ip\n",
    "\n",
    "\n",
    "class DriverOptions(object):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.options = Options()\n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--start-maximized')\n",
    "        self.options.add_argument('--start-fullscreen')\n",
    "        self.options.add_argument('--single-process')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        self.options.add_argument(\"--incognito\")\n",
    "        self.options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.options.add_experimental_option('useAutomationExtension', False)\n",
    "        self.options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        self.options.add_argument(\"disable-infobars\")\n",
    "\n",
    "        self.helperSpoofer = Spoofer()\n",
    "\n",
    "        self.options.add_argument('user-agent={}'.format(self.helperSpoofer.userAgent))\n",
    "        self.options.add_argument('--proxy-server=%s' % self.helperSpoofer.ip)\n",
    "\n",
    "\n",
    "class WebDriver(DriverOptions):\n",
    "\n",
    "    def __init__(self, path=''):\n",
    "        DriverOptions.__init__(self)\n",
    "        self.driver_instance = self.get_driver()\n",
    "\n",
    "    def get_driver(self):\n",
    "\n",
    "        print(\"\"\"\n",
    "        IP:{}\n",
    "        UserAgent: {}\n",
    "        \"\"\".format(self.helperSpoofer.ip, self.helperSpoofer.userAgent))\n",
    "\n",
    "        PROXY = self.helperSpoofer.ip\n",
    "        webdriver.DesiredCapabilities.CHROME['proxy'] = {\n",
    "            \"httpProxy\":PROXY,\n",
    "            \"ftpProxy\":PROXY,\n",
    "            \"sslProxy\":PROXY,\n",
    "            \"noProxy\":None,\n",
    "            \"proxyType\":\"MANUAL\",\n",
    "            \"autodetect\":False\n",
    "        }\n",
    "        webdriver.DesiredCapabilities.CHROME['acceptSslCerts'] = True\n",
    "\n",
    "        path = os.path.join(os.getcwd(), '/chromedriver.exe')\n",
    "\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "            \"source\":\n",
    "                \"const newProto = navigator.__proto__;\"\n",
    "                \"delete newProto.webdriver;\"\n",
    "                \"navigator.__proto__ = newProto;\"\n",
    "        })\n",
    "\n",
    "        return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(fields, rows, dirname, filename):\n",
    "    with open(dirname+filename, 'w', encoding='UTF8', newline='') as csvfile: \n",
    "        # creating a csv writer object\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(fields) \n",
    "        csvwriter.writerows(rows)\n",
    "    print(f\"Saved csv with name {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver creation failed.....Trying again\n",
      "\n",
      "        IP:20.47.108.204:8888\n",
      "        UserAgent: Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.93 Safari/537.36\n",
      "        \n",
      "Driver Successfully created\n"
     ]
    }
   ],
   "source": [
    "# Create anti bot detection web driver\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        driver = WebDriver()\n",
    "        break\n",
    "    except: # If Driver creation fails try again\n",
    "        print(\"Driver creation failed.....Trying again\")\n",
    "        continue\n",
    "print(\"Driver Successfully created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Driver instance and open the webpage through selenium\n",
    "\n",
    "driverinstance = driver.driver_instance\n",
    "url = \"https://www.expedia.com/Hotel-Search?adults=2&d1=2022-04-13&d2=2022-04-14&destination=Jaipur%2C%20Rajasthan%2C%20India&directFlights=false&endDate=2022-04-14&hotels-destination=Jaipur&hotels-destination=Jaisalmer&latLong=26.891643000499514%2C75.74652282695956&localDateFormat=M%2Fd%2Fyyyy&partialStay=false&regionId=1669&semdtl=&sort=RECOMMENDED&startDate=2022-04-13&theme=&useRewards=false&userIntent=\"\n",
    "driverinstance.get(url)\n",
    "\n",
    "# Click on the \"SHOW MORE\" button 20 times to load enough hotels \n",
    "for i in range(8):\n",
    "    sleep_time = 5 + 5*random.random()\n",
    "    time.sleep(sleep_time)\n",
    "    driverinstance.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    try:\n",
    "        button = driverinstance.find_element_by_xpath('//*[@class=\"uitk-button uitk-button-medium uitk-button-secondary\"]')\n",
    "        button.click()\n",
    "    except:\n",
    "        print(\"Button not Found, ending search\")\n",
    "        break\n",
    "\n",
    "# Create BeautifulSoup instance and search for each hotel on the page to get it's link\n",
    "\n",
    "soup = str(BeautifulSoup(driverinstance.page_source, 'html.parser'))\n",
    "soup = BeautifulSoup(soup, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ol = soup.find('ol' , class_  = 'results-list no-bullet').find_all('li', attrs={\"data-stid\":\"property-listing\"})\n",
    "\n",
    "hotel_url_li = []\n",
    "hotel_name_li = []\n",
    "hotel_price_li = []\n",
    "\n",
    "for li in ol:\n",
    "    hotel_url = li.find('a', class_='listing__link uitk-card-link')\n",
    "    hotel_name = li.find('h3' , class_='uitk-heading-5 is-visually-hidden')\n",
    "    # hotel_price_div = li.find('div', class_ = \"uitk-text uitk-type-600 uitk-type-bold uitk-text-emphasis-theme\")\n",
    "    try:\n",
    "        hotel_price = li.find('div', class_ = \"uitk-text uitk-type-600 uitk-type-bold uitk-text-emphasis-theme\").text\n",
    "    except:\n",
    "        hotel_price = \"\"\n",
    "    hotel_url_li.append(hotel_url)\n",
    "    hotel_name_li.append(hotel_name)\n",
    "    hotel_price_li.append(hotel_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "['$84', '$112', '$91', '$83', '$381', '$51', '$64', '$40', '$94', '$160', '$153', '$94', '$99', '$93', '$146', '$51', '$113', '$39', '$339', '$27', '$96', '$26', '$30', '$33', '$56', '$40', '$84', '$112', '$80', '$99', '$47', '$48', '$91', '$60', '$51', '$96', '$107', '$19', '$51', '$66', '$28', '$62', '$86', '$107', '$19', '$32', '$45', '$29', '$94', '$24', '$23', '$55', '$63', '$23', '$24', '$24', '$62', '$23', '$187', '$669', '$24', '$91', '$45', '$162', '$42', '$28', '$42', '$40', '$15', '$19', '$92', '$61', '$56', '$128', '$33', '$31', '$126', '$28', '$25', '$26', '$22', '$334', '$31', '$75', '$24', '$84', '$27', '$19', '$27', '$38', '$45', '$23', '$28', '$41', '$27', '$35', '$37', '$21', '$16', '$27', '$16', '$55', '$30', '$80', '$63', '$47', '$31', '$13', '$16', '$94', '$67', '$82', '$120', '$47', '$24', '$12', '$35', '$37', '$20', '$85', '$12', '$24', '$11', '$75', '$53', '$62', '$16', '$36', '$29', '$40', '$29', '$13', '$112', '$47', '$29', '$40', '$14', '$20', '$114', '$25', '$24', '$33', '$43', '$47', '$39', '$96', '$72', '$87', '$67', '$71', '$20', '$74', '$19', '$30', '$12', '$201', '$13', '$27', '$63', '$63', '$38', '$40', '$31', '$24', '$33', '$40', '$36', '$50', '$30', '$44', '$15', '$40', '$15', '$13', '$17', '$33', '$27', '$14', '$22', '$27', '$35', '$49', '$22', '$4', '$7', '$15', '$100', '$11', '$27', '$60', '$25', '$45', '$24', '$29', '$27', '$21', '$35', '$30', '$33', '$8', '$120', '$27', '$60', '$30', '$471', '$28', '$80', '$22', '$80', '$198', '$64', '$45', '$29', '$45', '$90', '$62', '$72', '$84', '$63', '$22', '$100', '$69', '$15', '$75', '$30', '$20', '$47', '$50', '$20', '$50', '$35', '$60', '$40', '$27', '$13', '$17', '$14', '$15', '$35', '$18', '$22', '$35', '$12', '$40', '$18', '$24', '$16', '$21', '$20', '$50', '$27', '$16', '$13', '$9', '$101', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(len(ol))\n",
    "print(hotel_price_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hotels found: 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hotel_url_list = []\n",
    "hotel_info = []\n",
    "\n",
    "hotel_length = len(hotel_url_li)\n",
    "print(f\"Number of hotels found: {hotel_length}\\n\")\n",
    "for i in range(hotel_length):\n",
    "    hotel_url_list.append(\"https://www.expedia.com\"+hotel_url_li[i].attrs['href'])\n",
    "    ls = [i+1, hotel_name_li[i].text, hotel_price_li[i][1:]]\n",
    "    hotel_info.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved csv with name Jaipur_hotels.csv\n"
     ]
    }
   ],
   "source": [
    "# Create CSV for name and price of the hotels\n",
    "\n",
    "fields = ['hotel_id', 'hotel_name', 'hotel_price']\n",
    "create_csv(fields, hotel_info, \"Project-Dataset/hotel urls/\", \"Jaipur_hotels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Jaisalmer\n",
      "1      Jaisalmer\n",
      "2      Jaisalmer\n",
      "3      Jaisalmer\n",
      "4      Jaisalmer\n",
      "         ...    \n",
      "148    Jaisalmer\n",
      "149    Jaisalmer\n",
      "150    Jaisalmer\n",
      "151    Jaisalmer\n",
      "152    Jaisalmer\n",
      "Name: city, Length: 153, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Project-Dataset/Jodhpur_hotel_info.csv')\n",
    "df.replace(to_replace='Jaisalmer', value = 'Jodhpur')\n",
    "print(df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the links in a text file\n",
    "\n",
    "with open(\"Project-Dataset/hotel urls/Jaipur_hotel_urls.txt\", 'w') as output:\n",
    "    for row in hotel_url_list:\n",
    "        output.write(str(row) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ac516125b3ee16d4eaa41f008fade7bad50b808bd1b6d74d2e8ae0015ba9066"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
